{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNjf2isl4NOPza534FdUVgC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c234e9bd81f4405489da4cd9a9e8900a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8dc1765571a0402cb866e33e1c87b22b",
              "IPY_MODEL_eed2b83c291042aaad14e9ea6c0a813b",
              "IPY_MODEL_ed3f04e4e72844399fcbba4592b9a3c2"
            ],
            "layout": "IPY_MODEL_fe63f854d3334fa694055f540a4fd7f3"
          }
        },
        "8dc1765571a0402cb866e33e1c87b22b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1e61cb4d970e45d0a05dbe46b6b9157f",
            "placeholder": "​",
            "style": "IPY_MODEL_a0adaafe2c8f40129c1da743b12dc503",
            "value": "  0%"
          }
        },
        "eed2b83c291042aaad14e9ea6c0a813b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4044527813f84799ad1c26d3487df818",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_12d86115f893476b82cd6af57765e2fb",
            "value": 0
          }
        },
        "ed3f04e4e72844399fcbba4592b9a3c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9ebbd817502f4bd3af12567bb5b1c754",
            "placeholder": "​",
            "style": "IPY_MODEL_5b46eb0c764f4f51abb5f5c4096776aa",
            "value": " 0/3 [01:29&lt;?, ?it/s]"
          }
        },
        "fe63f854d3334fa694055f540a4fd7f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1e61cb4d970e45d0a05dbe46b6b9157f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a0adaafe2c8f40129c1da743b12dc503": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4044527813f84799ad1c26d3487df818": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "12d86115f893476b82cd6af57765e2fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9ebbd817502f4bd3af12567bb5b1c754": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5b46eb0c764f4f51abb5f5c4096776aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hrnnikolov/ML_models/blob/main/model_deployment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup and Getting Data\n",
        "\n"
      ],
      "metadata": {
        "id": "1ciR7X2o8CEv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "xovQqgRxnuvs"
      },
      "outputs": [],
      "source": [
        "# # For this notebook to run with updated APIs, we need torch 1.12+ and torchvision 0.13+\n",
        "# try:\n",
        "#     import torch\n",
        "#     import torchvision\n",
        "#     assert int(torch.__version__.split(\".\")[1]) >= 12, \"torch version should be 1.12+\"\n",
        "#     assert int(torchvision.__version__.split(\".\")[1]) >= 13, \"torchvision version should be 0.13+\"\n",
        "#     print(f\"torch version: {torch.__version__}\")\n",
        "#     print(f\"torchvision version: {torchvision.__version__}\")\n",
        "# except:\n",
        "#     print(f\"[INFO] torch/torchvision versions not as required, installing nightly versions.\")\n",
        "#     !pip3 install -U torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu113\n",
        "#     import torch\n",
        "#     import torchvision\n",
        "#     print(f\"torch version: {torch.__version__}\")\n",
        "#     print(f\"torchvision version: {torchvision.__version__}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Continue with regular imports\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torchvision\n",
        "\n",
        "from torch import nn\n",
        "from torchvision import transforms\n",
        "\n",
        "# Try to get torchinfo, install it if it doesn't work\n",
        "try:\n",
        "    from torchinfo import summary\n",
        "except:\n",
        "    print(\"[INFO] Couldn't find torchinfo... installing it.\")\n",
        "    !pip install -q torchinfo\n",
        "    from torchinfo import summary\n",
        "\n",
        "# Try to import the going_modular directory, download it from GitHub if it doesn't work\n",
        "try:\n",
        "    from going_modular.going_modular import data_setup, engine\n",
        "    from helper_functions import download_data, set_seeds, plot_loss_curves\n",
        "except:\n",
        "    # Get the going_modular scripts\n",
        "    print(\"[INFO] Couldn't find going_modular or helper_functions scripts... downloading them from GitHub.\")\n",
        "    !git clone https://github.com/mrdbourke/pytorch-deep-learning\n",
        "    !mv pytorch-deep-learning/going_modular .\n",
        "    !mv pytorch-deep-learning/helper_functions.py . # get the helper_functions.py script\n",
        "    !rm -rf pytorch-deep-learning\n",
        "    from going_modular.going_modular import data_setup, engine\n",
        "    from helper_functions import download_data, set_seeds, plot_loss_curves"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3DBHY8US8O66",
        "outputId": "4b05f4c4-705a-4f14-e61a-a5348cf66ffb"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Couldn't find torchinfo... installing it.\n",
            "[INFO] Couldn't find going_modular or helper_functions scripts... downloading them from GitHub.\n",
            "Cloning into 'pytorch-deep-learning'...\n",
            "remote: Enumerating objects: 4056, done.\u001b[K\n",
            "remote: Total 4056 (delta 0), reused 0 (delta 0), pack-reused 4056\u001b[K\n",
            "Receiving objects: 100% (4056/4056), 646.90 MiB | 33.17 MiB/s, done.\n",
            "Resolving deltas: 100% (2371/2371), done.\n",
            "Updating files: 100% (248/248), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "owy6sk0O8QlK",
        "outputId": "eb758507-f365-4c3a-e6b2-b49efb043d4b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cpu'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download pizza, steak, sushi images from GitHub\n",
        "data_20_percent_path = download_data(source=\"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi_20_percent.zip\",\n",
        "                                     destination=\"pizza_steak_sushi_20_percent\")\n",
        "\n",
        "data_20_percent_path"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rdE4aIGa8cAR",
        "outputId": "98db341d-531e-4d3d-bd1a-87c2b91309de"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Did not find data/pizza_steak_sushi_20_percent directory, creating one...\n",
            "[INFO] Downloading pizza_steak_sushi_20_percent.zip from https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi_20_percent.zip...\n",
            "[INFO] Unzipping pizza_steak_sushi_20_percent.zip data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PosixPath('data/pizza_steak_sushi_20_percent')"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir = data_20_percent_path / 'train'\n",
        "test_dir = data_20_percent_path / 'test'\n",
        "\n",
        "train_dir, test_dir"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mcHT9lmFCE2e",
        "outputId": "fc1d3416-8966-4433-fa12-ed83bf8e7047"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(PosixPath('data/pizza_steak_sushi_20_percent/train'),\n",
              " PosixPath('data/pizza_steak_sushi_20_percent/test'))"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Creating Effnetb2 model"
      ],
      "metadata": {
        "id": "ykuNW9teYBsF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "effnetb2_weights = torchvision.models.EfficientNet_B2_Weights.DEFAULT\n",
        "\n",
        "effnetb2_transforms = effnetb2_weights.transforms()\n",
        "\n",
        "effnetb2 = torchvision.models.efficientnet_b2(weights=effnetb2_weights)\n",
        "\n",
        "for param in effnetb2.parameters():\n",
        "  param.requires_grad = False"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PxuTwPubH2VJ",
        "outputId": "538fed7f-5bd3-4436-b6f2-4850c2170a83"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/efficientnet_b2_rwightman-c35c1473.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_b2_rwightman-c35c1473.pth\n",
            "100%|██████████| 35.2M/35.2M [00:00<00:00, 87.6MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "effnetb2.classifier"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wS_lKkjpH2Mt",
        "outputId": "2dc767e2-0b1b-431c-a45b-b47bc6b9dd5c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Dropout(p=0.3, inplace=True)\n",
              "  (1): Linear(in_features=1408, out_features=1000, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "effnetb2.classifier = nn.Sequential(nn.Dropout(p=0.3, inplace=True),\n",
        "                                    nn.Linear(in_features=1408,\n",
        "                                              out_features=3))"
      ],
      "metadata": {
        "id": "5h0A8jbXH2KK"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_effnetb2_model(num_classes:int=3,\n",
        "                          seed:int=33):\n",
        "\n",
        "  effnetb2_weights = torchvision.models.EfficientNet_B2_Weights.DEFAULT\n",
        "\n",
        "  transforms = effnetb2_weights.transforms()\n",
        "\n",
        "  model = torchvision.models.efficientnet_b2(weights=effnetb2_weights)\n",
        "\n",
        "  for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "  torch.manual_seed(seed)\n",
        "\n",
        "  model.classifier = nn.Sequential(nn.Dropout(p=0.3, inplace=True),\n",
        "                                    nn.Linear(in_features=1408,\n",
        "                                              out_features=num_classes))\n",
        "\n",
        "  return model, transforms"
      ],
      "metadata": {
        "id": "PUnGOp8xI6BD"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "effnetb2, effnetb2_transforms = create_effnetb2_model(num_classes=3,\n",
        "                                                      seed=33)\n",
        "\n",
        "effnetb2, effnetb2_transforms"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tb8ssX3sI592",
        "outputId": "9d5ae997-1b24-45ed-ca3f-1fa7bca3aa6f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(EfficientNet(\n",
              "   (features): Sequential(\n",
              "     (0): Conv2dNormActivation(\n",
              "       (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "       (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "       (2): SiLU(inplace=True)\n",
              "     )\n",
              "     (1): Sequential(\n",
              "       (0): MBConv(\n",
              "         (block): Sequential(\n",
              "           (0): Conv2dNormActivation(\n",
              "             (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
              "             (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "             (2): SiLU(inplace=True)\n",
              "           )\n",
              "           (1): SqueezeExcitation(\n",
              "             (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "             (fc1): Conv2d(32, 8, kernel_size=(1, 1), stride=(1, 1))\n",
              "             (fc2): Conv2d(8, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "             (activation): SiLU(inplace=True)\n",
              "             (scale_activation): Sigmoid()\n",
              "           )\n",
              "           (2): Conv2dNormActivation(\n",
              "             (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "             (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "           )\n",
              "         )\n",
              "         (stochastic_depth): StochasticDepth(p=0.0, mode=row)\n",
              "       )\n",
              "       (1): MBConv(\n",
              "         (block): Sequential(\n",
              "           (0): Conv2dNormActivation(\n",
              "             (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)\n",
              "             (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "             (2): SiLU(inplace=True)\n",
              "           )\n",
              "           (1): SqueezeExcitation(\n",
              "             (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "             (fc1): Conv2d(16, 4, kernel_size=(1, 1), stride=(1, 1))\n",
              "             (fc2): Conv2d(4, 16, kernel_size=(1, 1), stride=(1, 1))\n",
              "             (activation): SiLU(inplace=True)\n",
              "             (scale_activation): Sigmoid()\n",
              "           )\n",
              "           (2): Conv2dNormActivation(\n",
              "             (0): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "             (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "           )\n",
              "         )\n",
              "         (stochastic_depth): StochasticDepth(p=0.008695652173913044, mode=row)\n",
              "       )\n",
              "     )\n",
              "     (2): Sequential(\n",
              "       (0): MBConv(\n",
              "         (block): Sequential(\n",
              "           (0): Conv2dNormActivation(\n",
              "             (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "             (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "             (2): SiLU(inplace=True)\n",
              "           )\n",
              "           (1): Conv2dNormActivation(\n",
              "             (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
              "             (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "             (2): SiLU(inplace=True)\n",
              "           )\n",
              "           (2): SqueezeExcitation(\n",
              "             (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "             (fc1): Conv2d(96, 4, kernel_size=(1, 1), stride=(1, 1))\n",
              "             (fc2): Conv2d(4, 96, kernel_size=(1, 1), stride=(1, 1))\n",
              "             (activation): SiLU(inplace=True)\n",
              "             (scale_activation): Sigmoid()\n",
              "           )\n",
              "           (3): Conv2dNormActivation(\n",
              "             (0): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "             (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "           )\n",
              "         )\n",
              "         (stochastic_depth): StochasticDepth(p=0.017391304347826087, mode=row)\n",
              "       )\n",
              "       (1): MBConv(\n",
              "         (block): Sequential(\n",
              "           (0): Conv2dNormActivation(\n",
              "             (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "             (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "             (2): SiLU(inplace=True)\n",
              "           )\n",
              "           (1): Conv2dNormActivation(\n",
              "             (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
              "             (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "             (2): SiLU(inplace=True)\n",
              "           )\n",
              "           (2): SqueezeExcitation(\n",
              "             (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "             (fc1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
              "             (fc2): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
              "             (activation): SiLU(inplace=True)\n",
              "             (scale_activation): Sigmoid()\n",
              "           )\n",
              "           (3): Conv2dNormActivation(\n",
              "             (0): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "             (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "           )\n",
              "         )\n",
              "         (stochastic_depth): StochasticDepth(p=0.026086956521739136, mode=row)\n",
              "       )\n",
              "       (2): MBConv(\n",
              "         (block): Sequential(\n",
              "           (0): Conv2dNormActivation(\n",
              "             (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "             (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "             (2): SiLU(inplace=True)\n",
              "           )\n",
              "           (1): Conv2dNormActivation(\n",
              "             (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
              "             (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "             (2): SiLU(inplace=True)\n",
              "           )\n",
              "           (2): SqueezeExcitation(\n",
              "             (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "             (fc1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
              "             (fc2): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
              "             (activation): SiLU(inplace=True)\n",
              "             (scale_activation): Sigmoid()\n",
              "           )\n",
              "           (3): Conv2dNormActivation(\n",
              "             (0): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "             (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "           )\n",
              "         )\n",
              "         (stochastic_depth): StochasticDepth(p=0.034782608695652174, mode=row)\n",
              "       )\n",
              "     )\n",
              "     (3): Sequential(\n",
              "       (0): MBConv(\n",
              "         (block): Sequential(\n",
              "           (0): Conv2dNormActivation(\n",
              "             (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "             (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "             (2): SiLU(inplace=True)\n",
              "           )\n",
              "           (1): Conv2dNormActivation(\n",
              "             (0): Conv2d(144, 144, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=144, bias=False)\n",
              "             (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "             (2): SiLU(inplace=True)\n",
              "           )\n",
              "           (2): SqueezeExcitation(\n",
              "             (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "             (fc1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
              "             (fc2): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
              "             (activation): SiLU(inplace=True)\n",
              "             (scale_activation): Sigmoid()\n",
              "           )\n",
              "           (3): Conv2dNormActivation(\n",
              "             (0): Conv2d(144, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "             (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "           )\n",
              "         )\n",
              "         (stochastic_depth): StochasticDepth(p=0.043478260869565216, mode=row)\n",
              "       )\n",
              "       (1): MBConv(\n",
              "         (block): Sequential(\n",
              "           (0): Conv2dNormActivation(\n",
              "             (0): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "             (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "             (2): SiLU(inplace=True)\n",
              "           )\n",
              "           (1): Conv2dNormActivation(\n",
              "             (0): Conv2d(288, 288, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=288, bias=False)\n",
              "             (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "             (2): SiLU(inplace=True)\n",
              "           )\n",
              "           (2): SqueezeExcitation(\n",
              "             (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "             (fc1): Conv2d(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
              "             (fc2): Conv2d(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
              "             (activation): SiLU(inplace=True)\n",
              "             (scale_activation): Sigmoid()\n",
              "           )\n",
              "           (3): Conv2dNormActivation(\n",
              "             (0): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "             (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "           )\n",
              "         )\n",
              "         (stochastic_depth): StochasticDepth(p=0.05217391304347827, mode=row)\n",
              "       )\n",
              "       (2): MBConv(\n",
              "         (block): Sequential(\n",
              "           (0): Conv2dNormActivation(\n",
              "             (0): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "             (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "             (2): SiLU(inplace=True)\n",
              "           )\n",
              "           (1): Conv2dNormActivation(\n",
              "             (0): Conv2d(288, 288, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=288, bias=False)\n",
              "             (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "             (2): SiLU(inplace=True)\n",
              "           )\n",
              "           (2): SqueezeExcitation(\n",
              "             (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "             (fc1): Conv2d(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
              "             (fc2): Conv2d(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
              "             (activation): SiLU(inplace=True)\n",
              "             (scale_activation): Sigmoid()\n",
              "           )\n",
              "           (3): Conv2dNormActivation(\n",
              "             (0): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "             (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "           )\n",
              "         )\n",
              "         (stochastic_depth): StochasticDepth(p=0.06086956521739131, mode=row)\n",
              "       )\n",
              "     )\n",
              "     (4): Sequential(\n",
              "       (0): MBConv(\n",
              "         (block): Sequential(\n",
              "           (0): Conv2dNormActivation(\n",
              "             (0): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "             (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "             (2): SiLU(inplace=True)\n",
              "           )\n",
              "           (1): Conv2dNormActivation(\n",
              "             (0): Conv2d(288, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=288, bias=False)\n",
              "             (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "             (2): SiLU(inplace=True)\n",
              "           )\n",
              "           (2): SqueezeExcitation(\n",
              "             (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "             (fc1): Conv2d(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
              "             (fc2): Conv2d(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
              "             (activation): SiLU(inplace=True)\n",
              "             (scale_activation): Sigmoid()\n",
              "           )\n",
              "           (3): Conv2dNormActivation(\n",
              "             (0): Conv2d(288, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "             (1): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "           )\n",
              "         )\n",
              "         (stochastic_depth): StochasticDepth(p=0.06956521739130435, mode=row)\n",
              "       )\n",
              "       (1): MBConv(\n",
              "         (block): Sequential(\n",
              "           (0): Conv2dNormActivation(\n",
              "             (0): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "             (1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "             (2): SiLU(inplace=True)\n",
              "           )\n",
              "           (1): Conv2dNormActivation(\n",
              "             (0): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)\n",
              "             (1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "             (2): SiLU(inplace=True)\n",
              "           )\n",
              "           (2): SqueezeExcitation(\n",
              "             (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "             (fc1): Conv2d(528, 22, kernel_size=(1, 1), stride=(1, 1))\n",
              "             (fc2): Conv2d(22, 528, kernel_size=(1, 1), stride=(1, 1))\n",
              "             (activation): SiLU(inplace=True)\n",
              "             (scale_activation): Sigmoid()\n",
              "           )\n",
              "           (3): Conv2dNormActivation(\n",
              "             (0): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "             (1): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "           )\n",
              "         )\n",
              "         (stochastic_depth): StochasticDepth(p=0.0782608695652174, mode=row)\n",
              "       )\n",
              "       (2): MBConv(\n",
              "         (block): Sequential(\n",
              "           (0): Conv2dNormActivation(\n",
              "             (0): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "             (1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "             (2): SiLU(inplace=True)\n",
              "           )\n",
              "           (1): Conv2dNormActivation(\n",
              "             (0): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)\n",
              "             (1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "             (2): SiLU(inplace=True)\n",
              "           )\n",
              "           (2): SqueezeExcitation(\n",
              "             (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "             (fc1): Conv2d(528, 22, kernel_size=(1, 1), stride=(1, 1))\n",
              "             (fc2): Conv2d(22, 528, kernel_size=(1, 1), stride=(1, 1))\n",
              "             (activation): SiLU(inplace=True)\n",
              "             (scale_activation): Sigmoid()\n",
              "           )\n",
              "           (3): Conv2dNormActivation(\n",
              "             (0): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "             (1): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "           )\n",
              "         )\n",
              "         (stochastic_depth): StochasticDepth(p=0.08695652173913043, mode=row)\n",
              "       )\n",
              "       (3): MBConv(\n",
              "         (block): Sequential(\n",
              "           (0): Conv2dNormActivation(\n",
              "             (0): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "             (1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "             (2): SiLU(inplace=True)\n",
              "           )\n",
              "           (1): Conv2dNormActivation(\n",
              "             (0): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)\n",
              "             (1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "             (2): SiLU(inplace=True)\n",
              "           )\n",
              "           (2): SqueezeExcitation(\n",
              "             (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "             (fc1): Conv2d(528, 22, kernel_size=(1, 1), stride=(1, 1))\n",
              "             (fc2): Conv2d(22, 528, kernel_size=(1, 1), stride=(1, 1))\n",
              "             (activation): SiLU(inplace=True)\n",
              "             (scale_activation): Sigmoid()\n",
              "           )\n",
              "           (3): Conv2dNormActivation(\n",
              "             (0): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "             (1): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "           )\n",
              "         )\n",
              "         (stochastic_depth): StochasticDepth(p=0.09565217391304348, mode=row)\n",
              "       )\n",
              "     )\n",
              "     (5): Sequential(\n",
              "       (0): MBConv(\n",
              "         (block): Sequential(\n",
              "           (0): Conv2dNormActivation(\n",
              "             (0): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "             (1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "             (2): SiLU(inplace=True)\n",
              "           )\n",
              "           (1): Conv2dNormActivation(\n",
              "             (0): Conv2d(528, 528, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=528, bias=False)\n",
              "             (1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "             (2): SiLU(inplace=True)\n",
              "           )\n",
              "           (2): SqueezeExcitation(\n",
              "             (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "             (fc1): Conv2d(528, 22, kernel_size=(1, 1), stride=(1, 1))\n",
              "             (fc2): Conv2d(22, 528, kernel_size=(1, 1), stride=(1, 1))\n",
              "             (activation): SiLU(inplace=True)\n",
              "             (scale_activation): Sigmoid()\n",
              "           )\n",
              "           (3): Conv2dNormActivation(\n",
              "             (0): Conv2d(528, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "             (1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "           )\n",
              "         )\n",
              "         (stochastic_depth): StochasticDepth(p=0.10434782608695654, mode=row)\n",
              "       )\n",
              "       (1): MBConv(\n",
              "         (block): Sequential(\n",
              "           (0): Conv2dNormActivation(\n",
              "             (0): Conv2d(120, 720, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "             (1): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "             (2): SiLU(inplace=True)\n",
              "           )\n",
              "           (1): Conv2dNormActivation(\n",
              "             (0): Conv2d(720, 720, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=720, bias=False)\n",
              "             (1): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "             (2): SiLU(inplace=True)\n",
              "           )\n",
              "           (2): SqueezeExcitation(\n",
              "             (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "             (fc1): Conv2d(720, 30, kernel_size=(1, 1), stride=(1, 1))\n",
              "             (fc2): Conv2d(30, 720, kernel_size=(1, 1), stride=(1, 1))\n",
              "             (activation): SiLU(inplace=True)\n",
              "             (scale_activation): Sigmoid()\n",
              "           )\n",
              "           (3): Conv2dNormActivation(\n",
              "             (0): Conv2d(720, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "             (1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "           )\n",
              "         )\n",
              "         (stochastic_depth): StochasticDepth(p=0.11304347826086956, mode=row)\n",
              "       )\n",
              "       (2): MBConv(\n",
              "         (block): Sequential(\n",
              "           (0): Conv2dNormActivation(\n",
              "             (0): Conv2d(120, 720, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "             (1): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "             (2): SiLU(inplace=True)\n",
              "           )\n",
              "           (1): Conv2dNormActivation(\n",
              "             (0): Conv2d(720, 720, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=720, bias=False)\n",
              "             (1): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "             (2): SiLU(inplace=True)\n",
              "           )\n",
              "           (2): SqueezeExcitation(\n",
              "             (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "             (fc1): Conv2d(720, 30, kernel_size=(1, 1), stride=(1, 1))\n",
              "             (fc2): Conv2d(30, 720, kernel_size=(1, 1), stride=(1, 1))\n",
              "             (activation): SiLU(inplace=True)\n",
              "             (scale_activation): Sigmoid()\n",
              "           )\n",
              "           (3): Conv2dNormActivation(\n",
              "             (0): Conv2d(720, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "             (1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "           )\n",
              "         )\n",
              "         (stochastic_depth): StochasticDepth(p=0.12173913043478261, mode=row)\n",
              "       )\n",
              "       (3): MBConv(\n",
              "         (block): Sequential(\n",
              "           (0): Conv2dNormActivation(\n",
              "             (0): Conv2d(120, 720, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "             (1): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "             (2): SiLU(inplace=True)\n",
              "           )\n",
              "           (1): Conv2dNormActivation(\n",
              "             (0): Conv2d(720, 720, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=720, bias=False)\n",
              "             (1): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "             (2): SiLU(inplace=True)\n",
              "           )\n",
              "           (2): SqueezeExcitation(\n",
              "             (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "             (fc1): Conv2d(720, 30, kernel_size=(1, 1), stride=(1, 1))\n",
              "             (fc2): Conv2d(30, 720, kernel_size=(1, 1), stride=(1, 1))\n",
              "             (activation): SiLU(inplace=True)\n",
              "             (scale_activation): Sigmoid()\n",
              "           )\n",
              "           (3): Conv2dNormActivation(\n",
              "             (0): Conv2d(720, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "             (1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "           )\n",
              "         )\n",
              "         (stochastic_depth): StochasticDepth(p=0.13043478260869565, mode=row)\n",
              "       )\n",
              "     )\n",
              "     (6): Sequential(\n",
              "       (0): MBConv(\n",
              "         (block): Sequential(\n",
              "           (0): Conv2dNormActivation(\n",
              "             (0): Conv2d(120, 720, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "             (1): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "             (2): SiLU(inplace=True)\n",
              "           )\n",
              "           (1): Conv2dNormActivation(\n",
              "             (0): Conv2d(720, 720, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=720, bias=False)\n",
              "             (1): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "             (2): SiLU(inplace=True)\n",
              "           )\n",
              "           (2): SqueezeExcitation(\n",
              "             (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "             (fc1): Conv2d(720, 30, kernel_size=(1, 1), stride=(1, 1))\n",
              "             (fc2): Conv2d(30, 720, kernel_size=(1, 1), stride=(1, 1))\n",
              "             (activation): SiLU(inplace=True)\n",
              "             (scale_activation): Sigmoid()\n",
              "           )\n",
              "           (3): Conv2dNormActivation(\n",
              "             (0): Conv2d(720, 208, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "             (1): BatchNorm2d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "           )\n",
              "         )\n",
              "         (stochastic_depth): StochasticDepth(p=0.1391304347826087, mode=row)\n",
              "       )\n",
              "       (1): MBConv(\n",
              "         (block): Sequential(\n",
              "           (0): Conv2dNormActivation(\n",
              "             (0): Conv2d(208, 1248, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "             (1): BatchNorm2d(1248, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "             (2): SiLU(inplace=True)\n",
              "           )\n",
              "           (1): Conv2dNormActivation(\n",
              "             (0): Conv2d(1248, 1248, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1248, bias=False)\n",
              "             (1): BatchNorm2d(1248, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "             (2): SiLU(inplace=True)\n",
              "           )\n",
              "           (2): SqueezeExcitation(\n",
              "             (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "             (fc1): Conv2d(1248, 52, kernel_size=(1, 1), stride=(1, 1))\n",
              "             (fc2): Conv2d(52, 1248, kernel_size=(1, 1), stride=(1, 1))\n",
              "             (activation): SiLU(inplace=True)\n",
              "             (scale_activation): Sigmoid()\n",
              "           )\n",
              "           (3): Conv2dNormActivation(\n",
              "             (0): Conv2d(1248, 208, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "             (1): BatchNorm2d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "           )\n",
              "         )\n",
              "         (stochastic_depth): StochasticDepth(p=0.14782608695652175, mode=row)\n",
              "       )\n",
              "       (2): MBConv(\n",
              "         (block): Sequential(\n",
              "           (0): Conv2dNormActivation(\n",
              "             (0): Conv2d(208, 1248, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "             (1): BatchNorm2d(1248, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "             (2): SiLU(inplace=True)\n",
              "           )\n",
              "           (1): Conv2dNormActivation(\n",
              "             (0): Conv2d(1248, 1248, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1248, bias=False)\n",
              "             (1): BatchNorm2d(1248, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "             (2): SiLU(inplace=True)\n",
              "           )\n",
              "           (2): SqueezeExcitation(\n",
              "             (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "             (fc1): Conv2d(1248, 52, kernel_size=(1, 1), stride=(1, 1))\n",
              "             (fc2): Conv2d(52, 1248, kernel_size=(1, 1), stride=(1, 1))\n",
              "             (activation): SiLU(inplace=True)\n",
              "             (scale_activation): Sigmoid()\n",
              "           )\n",
              "           (3): Conv2dNormActivation(\n",
              "             (0): Conv2d(1248, 208, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "             (1): BatchNorm2d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "           )\n",
              "         )\n",
              "         (stochastic_depth): StochasticDepth(p=0.1565217391304348, mode=row)\n",
              "       )\n",
              "       (3): MBConv(\n",
              "         (block): Sequential(\n",
              "           (0): Conv2dNormActivation(\n",
              "             (0): Conv2d(208, 1248, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "             (1): BatchNorm2d(1248, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "             (2): SiLU(inplace=True)\n",
              "           )\n",
              "           (1): Conv2dNormActivation(\n",
              "             (0): Conv2d(1248, 1248, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1248, bias=False)\n",
              "             (1): BatchNorm2d(1248, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "             (2): SiLU(inplace=True)\n",
              "           )\n",
              "           (2): SqueezeExcitation(\n",
              "             (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "             (fc1): Conv2d(1248, 52, kernel_size=(1, 1), stride=(1, 1))\n",
              "             (fc2): Conv2d(52, 1248, kernel_size=(1, 1), stride=(1, 1))\n",
              "             (activation): SiLU(inplace=True)\n",
              "             (scale_activation): Sigmoid()\n",
              "           )\n",
              "           (3): Conv2dNormActivation(\n",
              "             (0): Conv2d(1248, 208, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "             (1): BatchNorm2d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "           )\n",
              "         )\n",
              "         (stochastic_depth): StochasticDepth(p=0.16521739130434784, mode=row)\n",
              "       )\n",
              "       (4): MBConv(\n",
              "         (block): Sequential(\n",
              "           (0): Conv2dNormActivation(\n",
              "             (0): Conv2d(208, 1248, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "             (1): BatchNorm2d(1248, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "             (2): SiLU(inplace=True)\n",
              "           )\n",
              "           (1): Conv2dNormActivation(\n",
              "             (0): Conv2d(1248, 1248, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1248, bias=False)\n",
              "             (1): BatchNorm2d(1248, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "             (2): SiLU(inplace=True)\n",
              "           )\n",
              "           (2): SqueezeExcitation(\n",
              "             (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "             (fc1): Conv2d(1248, 52, kernel_size=(1, 1), stride=(1, 1))\n",
              "             (fc2): Conv2d(52, 1248, kernel_size=(1, 1), stride=(1, 1))\n",
              "             (activation): SiLU(inplace=True)\n",
              "             (scale_activation): Sigmoid()\n",
              "           )\n",
              "           (3): Conv2dNormActivation(\n",
              "             (0): Conv2d(1248, 208, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "             (1): BatchNorm2d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "           )\n",
              "         )\n",
              "         (stochastic_depth): StochasticDepth(p=0.17391304347826086, mode=row)\n",
              "       )\n",
              "     )\n",
              "     (7): Sequential(\n",
              "       (0): MBConv(\n",
              "         (block): Sequential(\n",
              "           (0): Conv2dNormActivation(\n",
              "             (0): Conv2d(208, 1248, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "             (1): BatchNorm2d(1248, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "             (2): SiLU(inplace=True)\n",
              "           )\n",
              "           (1): Conv2dNormActivation(\n",
              "             (0): Conv2d(1248, 1248, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1248, bias=False)\n",
              "             (1): BatchNorm2d(1248, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "             (2): SiLU(inplace=True)\n",
              "           )\n",
              "           (2): SqueezeExcitation(\n",
              "             (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "             (fc1): Conv2d(1248, 52, kernel_size=(1, 1), stride=(1, 1))\n",
              "             (fc2): Conv2d(52, 1248, kernel_size=(1, 1), stride=(1, 1))\n",
              "             (activation): SiLU(inplace=True)\n",
              "             (scale_activation): Sigmoid()\n",
              "           )\n",
              "           (3): Conv2dNormActivation(\n",
              "             (0): Conv2d(1248, 352, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "             (1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "           )\n",
              "         )\n",
              "         (stochastic_depth): StochasticDepth(p=0.1826086956521739, mode=row)\n",
              "       )\n",
              "       (1): MBConv(\n",
              "         (block): Sequential(\n",
              "           (0): Conv2dNormActivation(\n",
              "             (0): Conv2d(352, 2112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "             (1): BatchNorm2d(2112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "             (2): SiLU(inplace=True)\n",
              "           )\n",
              "           (1): Conv2dNormActivation(\n",
              "             (0): Conv2d(2112, 2112, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2112, bias=False)\n",
              "             (1): BatchNorm2d(2112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "             (2): SiLU(inplace=True)\n",
              "           )\n",
              "           (2): SqueezeExcitation(\n",
              "             (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "             (fc1): Conv2d(2112, 88, kernel_size=(1, 1), stride=(1, 1))\n",
              "             (fc2): Conv2d(88, 2112, kernel_size=(1, 1), stride=(1, 1))\n",
              "             (activation): SiLU(inplace=True)\n",
              "             (scale_activation): Sigmoid()\n",
              "           )\n",
              "           (3): Conv2dNormActivation(\n",
              "             (0): Conv2d(2112, 352, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "             (1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "           )\n",
              "         )\n",
              "         (stochastic_depth): StochasticDepth(p=0.19130434782608696, mode=row)\n",
              "       )\n",
              "     )\n",
              "     (8): Conv2dNormActivation(\n",
              "       (0): Conv2d(352, 1408, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "       (1): BatchNorm2d(1408, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "       (2): SiLU(inplace=True)\n",
              "     )\n",
              "   )\n",
              "   (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "   (classifier): Sequential(\n",
              "     (0): Dropout(p=0.3, inplace=True)\n",
              "     (1): Linear(in_features=1408, out_features=3, bias=True)\n",
              "   )\n",
              " ),\n",
              " ImageClassification(\n",
              "     crop_size=[288]\n",
              "     resize_size=[288]\n",
              "     mean=[0.485, 0.456, 0.406]\n",
              "     std=[0.229, 0.224, 0.225]\n",
              "     interpolation=InterpolationMode.BICUBIC\n",
              " ))"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating DataLoaders"
      ],
      "metadata": {
        "id": "B6ZHx3W7Mf4q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from going_modular.going_modular import data_setup\n",
        "import torchvision\n",
        "\n",
        "BATCH_SIZE=32\n",
        "\n",
        "train_dataloader, test_dataloader , class_names = data_setup.create_dataloaders(train_dir=train_dir,\n",
        "                                                                                test_dir=test_dir,\n",
        "                                                                                transform=effnetb2_transforms,\n",
        "                                                                                batch_size=BATCH_SIZE)"
      ],
      "metadata": {
        "id": "Jbb_bjH8Ct16"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader, class_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g8iww86LMfX0",
        "outputId": "da7233d9-7422-42cc-d9ad-ad09e813f945"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<torch.utils.data.dataloader.DataLoader at 0x7f4ea13cfe50>,\n",
              " ['pizza', 'steak', 'sushi'])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from going_modular.going_modular import engine\n",
        "\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(params=effnetb2.parameters(),\n",
        "                             lr=0.001)\n",
        "\n",
        "effnetb2_results = engine.train(model=effnetb2,\n",
        "             train_dataloader=train_dataloader,\n",
        "             test_dataloader=test_dataloader,\n",
        "             optimizer=optimizer,\n",
        "             loss_fn=loss_fn,\n",
        "             epochs=3,\n",
        "             device=device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 477,
          "referenced_widgets": [
            "c234e9bd81f4405489da4cd9a9e8900a",
            "8dc1765571a0402cb866e33e1c87b22b",
            "eed2b83c291042aaad14e9ea6c0a813b",
            "ed3f04e4e72844399fcbba4592b9a3c2",
            "fe63f854d3334fa694055f540a4fd7f3",
            "1e61cb4d970e45d0a05dbe46b6b9157f",
            "a0adaafe2c8f40129c1da743b12dc503",
            "4044527813f84799ad1c26d3487df818",
            "12d86115f893476b82cd6af57765e2fb",
            "9ebbd817502f4bd3af12567bb5b1c754",
            "5b46eb0c764f4f51abb5f5c4096776aa"
          ]
        },
        "id": "R9idKGgdMfVK",
        "outputId": "e0c974f1-efa0-49e9-c44f-0c154320096e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c234e9bd81f4405489da4cd9a9e8900a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-5d06612d9b5a>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m                              lr=0.001)\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m effnetb2_results = engine.train(model=effnetb2,\n\u001b[0m\u001b[1;32m      8\u001b[0m              \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m              \u001b[0mtest_dataloader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_dataloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/going_modular/going_modular/engine.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_dataloader, test_dataloader, optimizer, loss_fn, epochs, device)\u001b[0m\n\u001b[1;32m    167\u001b[0m     \u001b[0;31m# Loop through training and testing steps for a number of epochs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m         train_loss, train_acc = train_step(model=model,\n\u001b[0m\u001b[1;32m    170\u001b[0m                                           \u001b[0mdataloader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m                                           \u001b[0mloss_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/going_modular/going_modular/engine.py\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(model, dataloader, loss_fn, optimizer, device)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;31m# 1. Forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;31m# 2. Calculate  and accumulate loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/models/efficientnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 343\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/models/efficientnet.py\u001b[0m in \u001b[0;36m_forward_impl\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    331\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_forward_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 333\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mavgpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/models/efficientnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_res_connect\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstochastic_depth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/batchnorm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0mused\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mnormalization\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0;32min\u001b[0m \u001b[0meval\u001b[0m \u001b[0mmode\u001b[0m \u001b[0mwhen\u001b[0m \u001b[0mbuffers\u001b[0m \u001b[0mare\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \"\"\"\n\u001b[0;32m--> 175\u001b[0;31m         return F.batch_norm(\n\u001b[0m\u001b[1;32m    176\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m             \u001b[0;31m# If buffers are not to be tracked, ensure that they won't be updated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   2480\u001b[0m         \u001b[0m_verify_batch_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2481\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2482\u001b[0;31m     return torch.batch_norm(\n\u001b[0m\u001b[1;32m   2483\u001b[0m         \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2484\u001b[0m     )\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plot_loss_curves(effnetb2_results)"
      ],
      "metadata": {
        "id": "1xoSWRRBMfSC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from going_modular.going_modular import utils\n",
        "\n",
        "# Save the model\n",
        "utils.save_model(model=effnetb2,\n",
        "                 target_dir=\"models\",\n",
        "                 model_name=\"09_pretrained_effnetb2_feature_extractor_pizza_steak_sushi_20_percent.pth\")"
      ],
      "metadata": {
        "id": "_YhLsH0LMfPM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "\n",
        "pretrained_effnetb2_model_size = Path('models/09_pretrained_effnetb2_feature_extractor_pizza_steak_sushi_20_percent.pth').stat().st_size / (1024 * 1024)\n",
        "print(f'Your model size is {pretrained_effnetb2_model_size:.2f} mb')"
      ],
      "metadata": {
        "id": "_7bv-eYOMfMU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# effnetb2 stats"
      ],
      "metadata": {
        "id": "5XcMm1KiWYe6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#num of params\n",
        "effnetb2_total_params = sum(torch.numel(param) for param in effnetb2.parameters())\n",
        "effnetb2_total_params"
      ],
      "metadata": {
        "id": "Y3M8A8ChMfJT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# effnetb2 dic stats\n",
        "effnetb2_stats = {'test_loss': effnetb2_results['test_loss'][-1],\n",
        "                  'test_acc': effnetb2_results['test_acc'][-1],\n",
        "                  'number_of_parameters': effnetb2_total_params,\n",
        "                  'model_size (MB)': pretrained_effnetb2_model_size}\n",
        "\n",
        "effnetb2_stats\n"
      ],
      "metadata": {
        "id": "fllLA631MfGm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating ViT model"
      ],
      "metadata": {
        "id": "MI_Kx70DX3eQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vit = torchvision.models.vit_b_16()\n",
        "vit.heads"
      ],
      "metadata": {
        "id": "stdOYKV-Zs6i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_vitb16_model(num_classes:int=3,\n",
        "                        seed:int=33):\n",
        "  weights = torchvision.models.ViT_B_16_Weights.DEFAULT\n",
        "  transforms = weights.transforms()\n",
        "  model = torchvision.models.vit_b_16(weights=weights)\n",
        "\n",
        "  for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "  torch.manual_seed(seed)\n",
        "  model.heads = nn.Sequential(nn.Linear(in_features=768,\n",
        "                                         out_features=num_classes))\n",
        "\n",
        "  return model, transforms"
      ],
      "metadata": {
        "id": "QK5y6XJ9XalH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_vit_model(num_classes:int=3,\n",
        "                     seed:int=42):\n",
        "    \"\"\"Creates a ViT-B/16 feature extractor model and transforms.\n",
        "\n",
        "    Args:\n",
        "        num_classes (int, optional): number of target classes. Defaults to 3.\n",
        "        seed (int, optional): random seed value for output layer. Defaults to 42.\n",
        "\n",
        "    Returns:\n",
        "        model (torch.nn.Module): ViT-B/16 feature extractor model.\n",
        "        transforms (torchvision.transforms): ViT-B/16 image transforms.\n",
        "    \"\"\"\n",
        "    # Create ViT_B_16 pretrained weights, transforms and model\n",
        "    weights = torchvision.models.ViT_B_16_Weights.DEFAULT\n",
        "    transforms = weights.transforms()\n",
        "    model = torchvision.models.vit_b_16(weights=weights)\n",
        "\n",
        "    # Freeze all layers in model\n",
        "    for param in model.parameters():\n",
        "        param.requires_grad = False\n",
        "\n",
        "    # Change classifier head to suit our needs (this will be trainable)\n",
        "    torch.manual_seed(seed)\n",
        "    model.heads = nn.Sequential(nn.Linear(in_features=768, # keep this the same as original model\n",
        "                                          out_features=num_classes)) # update to reflect target number of classes\n",
        "\n",
        "    return model, transforms"
      ],
      "metadata": {
        "id": "_zqXk6greRuE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create ViT model and transforms\n",
        "vit, vit_transforms = create_vit_model(num_classes=3,\n",
        "                                       seed=42)\n"
      ],
      "metadata": {
        "id": "YpRTm8JNZ-Hj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup ViT DataLoaders\n",
        "from going_modular.going_modular import data_setup\n",
        "train_dataloader_vit, test_dataloader_vit, class_names = data_setup.create_dataloaders(train_dir=train_dir,\n",
        "                                                                                       test_dir=test_dir,\n",
        "                                                                                       transform=vit_transforms,\n",
        "                                                                                       batch_size=32)"
      ],
      "metadata": {
        "id": "RkXAynB0Z-E2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from going_modular.going_modular import engine\n",
        "\n",
        "# Setup optimizer\n",
        "optimizer = torch.optim.Adam(params=vit.parameters(),\n",
        "                             lr=1e-3)\n",
        "# Setup loss function\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "# Train ViT model with seeds set for reproducibility\n",
        "set_seeds()\n",
        "vit_results = engine.train(model=vit,\n",
        "                           train_dataloader=train_dataloader_vit,\n",
        "                           test_dataloader=test_dataloader_vit,\n",
        "                           epochs=3,\n",
        "                           optimizer=optimizer,\n",
        "                           loss_fn=loss_fn,\n",
        "                           device=device)"
      ],
      "metadata": {
        "id": "KNS57-CMZ-CK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from helper_functions import plot_loss_curves\n",
        "\n",
        "plot_loss_curves(vit_results)"
      ],
      "metadata": {
        "id": "Cttvd0-VZ9_F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from going_modular.going_modular import utils\n",
        "\n",
        "# Save the model\n",
        "utils.save_model(model=vit,\n",
        "                 target_dir=\"models\",\n",
        "                 model_name=\"09_pretrained_vitb16_feature_extractor_pizza_steak_sushi_20_percent.pth\")"
      ],
      "metadata": {
        "id": "HY-XPvkTcj_V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "\n",
        "pretrained_vit_model_size = Path('models/09_pretrained_vitb16_feature_extractor_pizza_steak_sushi_20_percent.pth').stat().st_size / (1024 * 1024)\n",
        "print(f'Your model size is {pretrained_vit_model_size:.2f} mb')"
      ],
      "metadata": {
        "id": "NkekBsWxfV6z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#num of params\n",
        "vit_total_params = sum(torch.numel(param) for param in vit.parameters())\n",
        "vit_total_params"
      ],
      "metadata": {
        "id": "ZCt20JuUfV4M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# effnetb2 dic stats\n",
        "vit_stats = {'test_loss': vit_results['test_loss'][-1],\n",
        "                  'test_acc': vit_results['test_acc'][-1],\n",
        "                  'number_of_parameters': vit_total_params,\n",
        "                  'model_size (MB)': pretrained_vit_model_size}\n",
        "\n",
        "vit_stats"
      ],
      "metadata": {
        "id": "NCPLiHzcfV1T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data_paths = list(Path(test_dir).glob('*/*.jpg'))\n",
        "test_data_paths"
      ],
      "metadata": {
        "id": "F9Cf0Vjnl_VZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pathlib\n",
        "import torch\n",
        "import torchvision\n",
        "\n",
        "from PIL import Image\n",
        "from timeit import default_timer as timer\n",
        "from tqdm.auto import tqdm\n",
        "from typing import List, Dict\n",
        "\n",
        "\n",
        "def pred_and_store(paths: List[pathlib.Path],\n",
        "                   model: torch.nn.Module,\n",
        "                   transform: torchvision.transforms,\n",
        "                   class_names: List[str],\n",
        "                   device: str = 'cuda' if torch.cuda.is_available() else 'cpu') ->List[Dict]:\n",
        "\n",
        "  pred_list = []\n",
        "\n",
        "  for path in tqdm(paths):\n",
        "    pred_dict = {}\n",
        "    pred_dict['image_path'] = path\n",
        "    class_name = path.parent.stem\n",
        "    pred_dict['class_name'] = class_name\n",
        "\n",
        "    start_time = timer()\n",
        "    img = Image.open(path)\n",
        "\n",
        "    transformed_image = transform(img).unsqueeze(0).to(device)\n",
        "\n",
        "    model = model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    with torch.inference_mode():\n",
        "      pred_logit = model(transformed_image) # perform inference on target sample\n",
        "      pred_prob = torch.softmax(pred_logit, dim=1) # turn logits into prediction probabilities\n",
        "      pred_label = torch.argmax(pred_prob, dim=1) # turn prediction probabilities into prediction label\n",
        "      pred_class = class_names[pred_label.cpu()] # hardcode prediction class to be on CPU\n",
        "\n",
        "      # 11. Make sure things in the dictionary are on CPU (required for inspecting predictions later on)\n",
        "      pred_dict[\"pred_prob\"] = round(pred_prob.unsqueeze(0).max().cpu().item(), 4)\n",
        "      pred_dict[\"pred_class\"] = pred_class\n",
        "\n",
        "      end_time = timer()\n",
        "      pred_dict['time_for_pred'] = round(end_time-start_time, 4)\n",
        "\n",
        "\n",
        "    pred_dict['correct'] = class_name == pred_class\n",
        "\n",
        "    pred_list.append(pred_dict)\n",
        "\n",
        "  return pred_list\n"
      ],
      "metadata": {
        "id": "5lkDtbcIl_MS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "effnetb2_test_pred_dicts = pred_and_store(paths=test_data_paths,\n",
        "                                          model=effnetb2,\n",
        "                                          transform=effnetb2_transforms,\n",
        "                                          class_names=class_names,\n",
        "                                          device='cpu')"
      ],
      "metadata": {
        "id": "X17fxT9el_Ib"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "effnetb2_test_pred_dicts"
      ],
      "metadata": {
        "id": "r9Mn-6q1fVsw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "effnetb2_test_pred_df = pd.DataFrame(effnetb2_test_pred_dicts)\n",
        "effnetb2_test_pred_df.head()"
      ],
      "metadata": {
        "id": "FhCwvQ5JU_PQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Find the average time per prediction\n",
        "effnetb2_average_time_per_pred = round(effnetb2_test_pred_df.time_for_pred.mean(), 4)\n",
        "print(f\"EffNetB2 average time per prediction: {effnetb2_average_time_per_pred} seconds\")"
      ],
      "metadata": {
        "id": "lhPsYSSpU_M_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vit_test_pred_dicts = pred_and_store(paths=test_data_paths,\n",
        "                                          model=vit,\n",
        "                                          transform=vit_transforms,\n",
        "                                          class_names=class_names,\n",
        "                                          device='cpu')"
      ],
      "metadata": {
        "id": "tfBzI8c2U_KZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "vit_test_pred_df = pd.DataFrame(vit_test_pred_dicts)\n",
        "vit_test_pred_df.head()"
      ],
      "metadata": {
        "id": "S08ffXQkU_IJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Find the average time per prediction\n",
        "vit_average_time_per_pred = round(vit_test_pred_df.time_for_pred.mean(), 4)\n",
        "print(f\"ViT average time per prediction: {vit_average_time_per_pred} seconds\")"
      ],
      "metadata": {
        "id": "NSvHZJjrU_Fn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Count the number of correct predictions\n",
        "vit_test_pred_df.correct.value_counts()"
      ],
      "metadata": {
        "id": "V5JGWJchU_DF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add average prediction time for ViT model on CPU\n",
        "vit_stats[\"time_per_pred_cpu\"] = vit_average_time_per_pred\n",
        "vit_stats"
      ],
      "metadata": {
        "id": "YZtuJcmkU_Az"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add EffNetB2 average prediction time to stats dictionary\n",
        "effnetb2_stats[\"time_per_pred_cpu\"] = effnetb2_average_time_per_pred\n",
        "effnetb2_stats"
      ],
      "metadata": {
        "id": "3l09lPOkXRXc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame([effnetb2_stats, vit_stats])\n",
        "\n",
        "df['model'] = ['EffNetB2', 'ViT']\n",
        "\n",
        "df['test_acc'] = round(df['test_acc'] * 100, 2)\n",
        "df"
      ],
      "metadata": {
        "id": "zILaTJWJXbfn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(data=(df.set_index('model').loc['ViT'] / df.set_index('model').loc['EffNetB2']),\n",
        "             columns=['ViT to EffNetB2 ratios']).T"
      ],
      "metadata": {
        "id": "Eayki1q5Xbco"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "SQZYJSDMbI9y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Create a plot from model comparison DataFrame\n",
        "fig, ax = plt.subplots(figsize=(12, 8))\n",
        "scatter = ax.scatter(data=df,\n",
        "                     x=\"time_per_pred_cpu\",\n",
        "                     y=\"test_acc\",\n",
        "                     c=[\"blue\", \"orange\"], # what colours to use?\n",
        "                     s=\"model_size (MB)\") # size the dots by the model sizes\n",
        "\n",
        "# 2. Add titles, labels and customize fontsize for aesthetics\n",
        "ax.set_title(\"FoodVision Mini Inference Speed vs Performance\", fontsize=18)\n",
        "ax.set_xlabel(\"Prediction time per image (seconds)\", fontsize=14)\n",
        "ax.set_ylabel(\"Test accuracy (%)\", fontsize=14)\n",
        "ax.tick_params(axis='both', labelsize=12)\n",
        "ax.grid('True')\n",
        "\n",
        "for index, row in df.iterrows():\n",
        "  ax.annotate(text=row[\"model\"], # note: depending on your version of Matplotlib, you may need to use \"s=...\" or \"text=...\", see: https://github.com/faustomorales/keras-ocr/issues/183#issuecomment-977733270\n",
        "                xy=(row[\"time_per_pred_cpu\"]+0.0006, row[\"test_acc\"]+0.03),\n",
        "                size=12)\n",
        "\n",
        "handles, labels = scatter.legend_elements(prop='sizes', alpha=0.5)\n",
        "model_size_legend = ax.legend(handles,\n",
        "                              labels,\n",
        "                              loc='lower right',\n",
        "                              title='Model size (MB)',\n",
        "                              fontsize=12)\n",
        "\n",
        "# Save the figure\n",
        "plt.savefig(\"09-foodvision-mini-inference-speed-vs-performance.jpg\")\n",
        "\n",
        "# Show the figure\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "hM0K6HeCXbZ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating a Gradio Demo"
      ],
      "metadata": {
        "id": "bQxkkmPOgvmL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import/install Gradio\n",
        "try:\n",
        "    import gradio as gr\n",
        "except:\n",
        "    !pip -q install gradio\n",
        "    import gradio as gr\n",
        "\n",
        "print(f\"Gradio version: {gr.__version__}\")"
      ],
      "metadata": {
        "id": "p3RuUKvIXbXG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Creating a function to map our inputs and outputs"
      ],
      "metadata": {
        "id": "mSG54RX31rxO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "effnetb2 = effnetb2.to('cpu')\n",
        "\n",
        "next(iter(effnetb2.parameters())).device"
      ],
      "metadata": {
        "id": "HXx0DlG5XbUX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Tuple, Dict\n",
        "\n",
        "def predict(img) -> Tuple[Dict, float]:\n",
        "\n",
        "  start_time = timer()\n",
        "\n",
        "  #transform image\n",
        "  img = effnetb2_transforms(img).unsqueeze(0)\n",
        "\n",
        "  #put model in eval mode and make prediction\n",
        "  effnetb2.eval()\n",
        "  with torch.inference_mode():\n",
        "    pred_probs = torch.softmax(effnetb2(img), dim=1)\n",
        "\n",
        "  #create a pred label and pred probability dict\n",
        "  pred_labels_and_probs = {class_names[i]: float(pred_probs[0][i]) for i in range(len(class_names))}\n",
        "\n",
        "  #calc pred time\n",
        "  end_time = timer()\n",
        "  pred_time = round(end_time - start_time, 4)\n",
        "  return pred_labels_and_probs, pred_time"
      ],
      "metadata": {
        "id": "uivCjHWtXbR-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "from PIL import Image\n",
        "\n",
        "#Get a list of all test image filepath\n",
        "test_data_paths = list(Path(test_dir).glob('*/*.jpg'))\n",
        "\n",
        "#randomly select a test image path\n",
        "random_image_path = random.sample(test_data_paths, k=1)[0]\n",
        "\n",
        "#open target image\n",
        "image = Image.open(random_image_path)\n",
        "print(f'[INFO] Predict on image at path {random_image_path}\\n')\n",
        "\n",
        "#Predict on random image and print out the outputs\n",
        "pred_dict, pred_time = predict(img=image)\n",
        "print(pred_dict)\n",
        "print(pred_time)"
      ],
      "metadata": {
        "id": "TLKwQmuuXbO8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create a list of examples"
      ],
      "metadata": {
        "id": "D6Co74IYQKi6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "example_list = [[str(filepath)] for filepath in random.sample(test_data_paths, k=3)]\n",
        "example_list"
      ],
      "metadata": {
        "id": "p8oTVssCXbMa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Build a Gradio Interface"
      ],
      "metadata": {
        "id": "dq5G3mjSRjKV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "title = 'FoodVision Mini 🍕🥩🍣'\n",
        "description = \"An EfficientNetB2 feature extractor computer vision model to classify images of food as pizza, steak or sushi.\"\n",
        "#article = \"Created at [09. PyTorch Model Deployment]\"\n",
        "\n",
        "demo = gr.Interface(inputs=gr.Image(type='pil'),\n",
        "                    outputs=[gr.Label(num_top_classes=3, label='Predictions'),\n",
        "                             gr.Number(label='Prediction time (s)')],\n",
        "                    examples=example_list,\n",
        "                    fn=predict,\n",
        "                    title=title,\n",
        "                    description=description)\n",
        "\n",
        "demo.launch(debug=False,\n",
        "            share=True)"
      ],
      "metadata": {
        "id": "z8TkqR79RihX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Turning Gradio Demot into a deployable app"
      ],
      "metadata": {
        "id": "Ac5sOt2mW7Fg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "from pathlib import Path\n",
        "\n",
        "#create demo path\n",
        "foodvision_mini_demo_path = Path('demos/foodvision_mini/')\n",
        "\n",
        "#remove files that might exist and create a new directory\n",
        "if foodvision_mini_demo_path.exists():\n",
        "  shutil.rmtree(foodvision_mini_demo_path)\n",
        "  foodvision_mini_demo_path.mkdir(parents=True,\n",
        "                                  exist_ok=True)\n",
        "else:\n",
        "  foodvision_mini_demo_path.mkdir(parents=True,\n",
        "                                  exist_ok=True)\n",
        "\n",
        "!ls demos/foodvision_mini/"
      ],
      "metadata": {
        "id": "1MT7O0yNXaed"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "from pathlib import Path\n",
        "\n",
        "#create an example direct\n",
        "foodvision_mini_example_path = foodvision_mini_demo_path / 'examples'\n",
        "foodvision_mini_example_path.mkdir(parents=True,\n",
        "                                   exist_ok=True)\n",
        "\n",
        "# 2. Collect three random test dataset image paths\n",
        "foodvision_mini_examples = [Path('data/pizza_steak_sushi_20_percent/test/sushi/592799.jpg'),\n",
        "                            Path('data/pizza_steak_sushi_20_percent/test/steak/3622237.jpg'),\n",
        "                            Path('data/pizza_steak_sushi_20_percent/test/pizza/2582289.jpg')]\n",
        "\n",
        "# copy the 3 images to the examples dir\n",
        "for example in foodvision_mini_examples:\n",
        "  destination = foodvision_mini_example_path / example.name\n",
        "  print(f'[INFO] Copying {example} to {destination}')\n",
        "  shutil.copy2(src=example,\n",
        "               dst=destination)"
      ],
      "metadata": {
        "id": "UpgZlLuxZePY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "example_list = [['examples/' + example] for example in os.listdir(foodvision_mini_example_path)]\n",
        "example_list"
      ],
      "metadata": {
        "id": "OdFQq-ZmgAwx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Moving the effnetb2 model\n",
        "\n",
        "import shutil\n",
        "#source\n",
        "effnetb2_foodvision_mini_model_path = '/content/models/09_pretrained_effnetb2_feature_extractor_pizza_steak_sushi_20_percent.pth'\n",
        "\n",
        "#destination\n",
        "effnetb2_foodvision_mini_model_destination = foodvision_mini_demo_path / effnetb2_foodvision_mini_model_path.split(\"/\")[-1]\n",
        "\n",
        "# try to move the model file\n",
        "try:\n",
        "    print(f\"[INFO] Attempting to move {effnetb2_foodvision_mini_model_path} to {effnetb2_foodvision_mini_model_destination}\")\n",
        "\n",
        "    # Move the model\n",
        "    shutil.move(src=effnetb2_foodvision_mini_model_path,\n",
        "                dst=effnetb2_foodvision_mini_model_destination)\n",
        "\n",
        "    print(f\"[INFO] Model move complete.\")\n",
        "\n",
        "# If the model has already been moved, check if it exists\n",
        "except:\n",
        "    print(f\"[INFO] No model found at {effnetb2_foodvision_mini_model_path}, perhaps its already been moved?\")\n",
        "    print(f\"[INFO] Model exists at {effnetb2_foodvision_mini_model_destination}: {effnetb2_foodvision_mini_model_destination.exists()}\")"
      ],
      "metadata": {
        "id": "uBOzIL07gseZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Turning effnetb2 model into a python script"
      ],
      "metadata": {
        "id": "cWmLLZPWkvz8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile demos/foodvision_mini/model.py\n",
        "import torch\n",
        "import torchvision\n",
        "from torch import nn\n",
        "\n",
        "def create_effnetb2_model(num_classes:int=3,\n",
        "                          seed:int=33):\n",
        "\n",
        "  effnetb2_weights = torchvision.models.EfficientNet_B2_Weights.DEFAULT\n",
        "\n",
        "  transforms = effnetb2_weights.transforms()\n",
        "\n",
        "  model = torchvision.models.efficientnet_b2(weights=effnetb2_weights)\n",
        "\n",
        "  for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "  torch.manual_seed(seed)\n",
        "\n",
        "  model.classifier = nn.Sequential(nn.Dropout(p=0.3, inplace=True),\n",
        "                                    nn.Linear(in_features=1408,\n",
        "                                              out_features=num_classes))\n",
        "\n",
        "  return model, transforms"
      ],
      "metadata": {
        "id": "uL4Ugbocjy3A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_names"
      ],
      "metadata": {
        "id": "nR3pLZ6alg8u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile demos/foodvision_mini/app.py\n",
        "# imports and class_names\n",
        "import gradio as gr\n",
        "import os\n",
        "import torch\n",
        "\n",
        "from model import create_effnetb2_model\n",
        "from timeit import default_timer as timer\n",
        "from typing import Tuple, Dict\n",
        "\n",
        "class_names = ['pizza', 'steak', 'sushi']\n",
        "\n",
        "# model and transforms\n",
        "effnetb2, effnetb2_transforms = create_effnetb2_model(\n",
        "    num_classes = len(class_names)\n",
        ")\n",
        "\n",
        "\n",
        "effnetb2.load_state_dict(\n",
        "    torch.load(\n",
        "        f'09_pretrained_effnetb2_feature_extractor_pizza_steak_sushi_20_percent.pth',\n",
        "        map_location=torch.device('cpu')\n",
        "    )\n",
        ")\n",
        "\n",
        "# pred fn\n",
        "def predict(img) -> Tuple[Dict, float]:\n",
        "\n",
        "  start_time = timer()\n",
        "\n",
        "  #transform image\n",
        "  img = effnetb2_transforms(img).unsqueeze(0)\n",
        "\n",
        "  #put model in eval mode and make prediction\n",
        "  effnetb2.eval()\n",
        "  with torch.inference_mode():\n",
        "    pred_probs = torch.softmax(effnetb2(img), dim=1)\n",
        "\n",
        "  #create a pred label and pred probability dict\n",
        "  pred_labels_and_probs = {class_names[i]: float(pred_probs[0][i]) for i in range(len(class_names))}\n",
        "\n",
        "  #calc pred time\n",
        "  end_time = timer()\n",
        "  pred_time = round(end_time - start_time, 4)\n",
        "  return pred_labels_and_probs, pred_time\n",
        "\n",
        "#Gradio app\n",
        "\n",
        "title = 'FoodVision Mini 🍕🥩🍣'\n",
        "description = \"An EfficientNetB2 feature extractor computer vision model to classify images of food as pizza, steak or sushi.\"\n",
        "\n",
        "#create example list\n",
        "example_list = [['examples/' + example] for example in os.listdir('examples')]\n",
        "\n",
        "demo = gr.Interface(inputs=gr.Image(type='pil'),\n",
        "                    outputs=[gr.Label(num_top_classes=3, label='Predictions'),\n",
        "                             gr.Number(label='Prediction time (s)')],\n",
        "                    examples=example_list,\n",
        "                    fn=predict,\n",
        "                    title=title,\n",
        "                    description=description)\n",
        "\n",
        "demo.launch(debug=False,\n",
        "            share=True)"
      ],
      "metadata": {
        "id": "EuOiHgrblg6E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating requirements.txt"
      ],
      "metadata": {
        "id": "E6s5lAmqpS2i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile demos/foodvision_mini/requirements.txt\n",
        "torch==2.2.2\n",
        "torchvision==0.17.2\n",
        "gr==4.26.0"
      ],
      "metadata": {
        "id": "vFkdjnVGlg3U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download the files and then upload them"
      ],
      "metadata": {
        "id": "2d1H4tIBq8e6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cd demos/foodvision_mini && zip -r ../foodvision_mini.zip * -x '*.pyc' '*.ipynb' '*.pycache*' '*.ipynb_checkpoints*'"
      ],
      "metadata": {
        "id": "TDxowe2dlgr6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# #downloading\n",
        "# try:\n",
        "#     from google.colab import files\n",
        "#     files.download(\"demos/foodvision_mini.zip\")\n",
        "# except:\n",
        "#     print(\"Not running in Google Colab, can't use google.colab.files.download(), please manually download.\")"
      ],
      "metadata": {
        "id": "N2lY8pxvlgpI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating a model for FooVision Big"
      ],
      "metadata": {
        "id": "7uBBzDwm8aGB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "effnetb2_food101, effnetb2_transforms = create_effnetb2_model(num_classes=101)"
      ],
      "metadata": {
        "id": "XMCzF_mO8sOT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "effnetb2_transforms"
      ],
      "metadata": {
        "id": "I4S1ykQ68sk5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Training data\n",
        "food101_train_transforms = torchvision.transforms.Compose([\n",
        "    torchvision.transforms.TrivialAugmentWide(),\n",
        "    effnetb2_transforms])"
      ],
      "metadata": {
        "id": "pBLIrsRr8shd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "food101_train_transforms"
      ],
      "metadata": {
        "id": "gdhz2s-08sez"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#testing data\n",
        "effnetb2_train_transforms = effnetb2_transforms"
      ],
      "metadata": {
        "id": "wuW-t_Nz8sRm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import datasets\n",
        "\n",
        "#setup data directory\n",
        "from pathlib import Path\n",
        "data_dir = Path('data')\n",
        "\n",
        "#Get_training data\n",
        "train_data = datasets.Food101(root=data_dir,\n",
        "                              split='train',\n",
        "                              transform=food101_train_transforms,\n",
        "                              download=True)\n",
        "\n",
        "# #Get testing data\n",
        "# test_data = datasets.Food101(root=data_dir,\n",
        "#                              split='test',\n",
        "#                              transform=effnetb2_transforms,#dont perform data qugumentation\n",
        "#                              download=True)"
      ],
      "metadata": {
        "id": "-vUXQAYk94P7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Get testing data\n",
        "test_data = datasets.Food101(root=data_dir,\n",
        "                             split='test',\n",
        "                             transform=effnetb2_transforms,#dont perform data qugumentation\n",
        "                             download=True)"
      ],
      "metadata": {
        "id": "q-Vbs3gWjv2x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "food101_class_names = train_data.classes\n",
        "food101_class_names[:25]"
      ],
      "metadata": {
        "id": "j3eO7-gDlOFZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Create a subset for faster experimenting"
      ],
      "metadata": {
        "id": "TvB2z6zFnSgp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import random_split\n",
        "\n",
        "def split_datasets(dataset:torchvision.datasets,\n",
        "                   split_size:float=0.2,\n",
        "                   seed:int=33):\n",
        "  #create split lenghts\n",
        "  length_1 = int(len(dataset) * split_size)\n",
        "  length_2 = len(dataset) - length_1\n",
        "\n",
        "  print(f'[INFO] Spliting dataset of length {len(dataset)} into splits of size : {length_1} and {length_2}')\n",
        "\n",
        "  #Create splits with given random seed\n",
        "  random_split_1, random_split_2 = torch.utils.data.random_split(dataset,\n",
        "                                                                 lengths=[length_1, length_2],\n",
        "                                                                 generator=torch.manual_seed(seed))\n",
        "\n",
        "  return random_split_1, random_split_2"
      ],
      "metadata": {
        "id": "HJZGwB5ZnAM8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_food101_20_percent, _ = split_datasets(dataset=train_data,\n",
        "                                                  split_size=0.2)\n",
        "\n",
        "test_data_food101_20_percent, _ = split_datasets(dataset=test_data,\n",
        "                                                 split_size=0.2)"
      ],
      "metadata": {
        "id": "XOtAF_UvpfvI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 32\n",
        "NUM_WORKERS = 2\n",
        "\n",
        "train_101_dataloader= torch.utils.data.DataLoader(dataset=train_data_food101_20_percent,\n",
        "                                                  batch_size=BATCH_SIZE,\n",
        "                                                  shuffle=True,\n",
        "                                                  num_workers=NUM_WORKERS)\n",
        "\n",
        "test_101_dataloader= torch.utils.data.DataLoader(dataset=test_data_food101_20_percent,\n",
        "                                                  batch_size=BATCH_SIZE,\n",
        "                                                  shuffle=False,\n",
        "                                                  num_workers=NUM_WORKERS)"
      ],
      "metadata": {
        "id": "XPsgpvYZqJg9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Training**"
      ],
      "metadata": {
        "id": "SbmYBIY0r6jB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from going_modular.going_modular import engine\n",
        "\n",
        "loss_fn = torch.nn.CrossEntropyLoss(label_smoothing=0.1)\n",
        "optimizer = torch.optim.Adam(params=effnetb2_food101.parameters(),\n",
        "                             lr=0.001)\n",
        "\n",
        "effnetb2_food101_results = engine.train(model=effnetb2_food101,\n",
        "                                        train_dataloader=train_101_dataloader,\n",
        "                                        test_dataloader=test_101_dataloader,\n",
        "                                        optimizer=optimizer,\n",
        "                                        loss_fn=loss_fn,\n",
        "                                        epochs=5,\n",
        "                                        device=device)"
      ],
      "metadata": {
        "id": "6z5lbdYer2UJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from helper_functions import plot_loss_curves\n",
        "\n",
        "plot_loss_curves(effnetb2_food101_results)"
      ],
      "metadata": {
        "id": "l2NBIZgdr2P_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from going_modular.going_modular import utils\n",
        "\n",
        "# Create a model path\n",
        "effnetb2_food101_model_path = \"09_pretrained_effnetb2_feature_extractor_food101_20_percent.pth\"\n",
        "\n",
        "# Save FoodVision Big model\n",
        "utils.save_model(model=effnetb2_food101,\n",
        "                 target_dir=\"models\",\n",
        "                 model_name=effnetb2_food101_model_path)"
      ],
      "metadata": {
        "id": "mv75d8qAr2NM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_effnetb2_food101, effnetb2_transforms =create_effnetb2_model(num_classes=101)\n",
        "\n",
        "#load the saved models state dict\n",
        "loaded_effnetb2_food101.load_state_dict(torch.load('models/09_pretrained_effnetb2_feature_extractor_food101_20_percent.pth'))"
      ],
      "metadata": {
        "id": "E4ULE2Dfr2Ka"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "\n",
        "# Get the model size in bytes then convert to megabytes\n",
        "pretrained_effnetb2_food101_model_size = Path(\"models\", effnetb2_food101_model_path).stat().st_size // (1024*1024) # division converts bytes to megabytes (roughly)\n",
        "print(f\"Pretrained EffNetB2 feature extractor Food101 model size: {pretrained_effnetb2_food101_model_size} MB\")"
      ],
      "metadata": {
        "id": "lZJX6lS3r2Hl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 100% of the data"
      ],
      "metadata": {
        "id": "5XLXpPSQ2CSi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 32\n",
        "NUM_WORKERS = 2\n",
        "\n",
        "train_101_dataloader_big = torch.utils.data.DataLoader(dataset=train_data,\n",
        "                                                  batch_size=BATCH_SIZE,\n",
        "                                                  shuffle=True,\n",
        "                                                  num_workers=NUM_WORKERS)\n",
        "\n",
        "test_101_dataloader_big = torch.utils.data.DataLoader(dataset=test_data,\n",
        "                                                  batch_size=BATCH_SIZE,\n",
        "                                                  shuffle=False,\n",
        "                                                  num_workers=NUM_WORKERS)"
      ],
      "metadata": {
        "id": "otGw3Uezr2E8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_101_dataloader_big)"
      ],
      "metadata": {
        "id": "xWJYBIHKr2CR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from going_modular.going_modular import engine\n",
        "\n",
        "loss_fn = torch.nn.CrossEntropyLoss(label_smoothing=0.1)\n",
        "optimizer = torch.optim.Adam(params=effnetb2_food101.parameters(),\n",
        "                             lr=0.001)\n",
        "\n",
        "effnetb2_food101_big_results = engine.train(model=effnetb2_food101,\n",
        "                                        train_dataloader=train_101_dataloader,\n",
        "                                        test_dataloader=test_101_dataloader_big,\n",
        "                                        optimizer=optimizer,\n",
        "                                        loss_fn=loss_fn,\n",
        "                                        epochs=5,\n",
        "                                        device=device)"
      ],
      "metadata": {
        "id": "bLrFgbytr1_g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from helper_functions import plot_loss_curves\n",
        "\n",
        "plot_loss_curves(effnetb2_food101_big_results)"
      ],
      "metadata": {
        "id": "ReEUO-IWr18y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from going_modular.going_modular import utils\n",
        "\n",
        "# Create a model path\n",
        "effnetb2_food101_big_model_path = \"09_pretrained_effnetb2_feature_extractor_food101_big.pth\"\n",
        "\n",
        "# Save FoodVision Big model\n",
        "utils.save_model(model=effnetb2_food101,\n",
        "                 target_dir=\"models\",\n",
        "                 model_name=effnetb2_food101_big_model_path)"
      ],
      "metadata": {
        "id": "sW0PnhMJ2pCv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_effnetb2_food101_big, effnetb2_transforms =create_effnetb2_model(num_classes=101)\n",
        "\n",
        "#load the saved models state dict\n",
        "loaded_effnetb2_food101_big.load_state_dict(torch.load('models/09_pretrained_effnetb2_feature_extractor_food101_big.pth'))"
      ],
      "metadata": {
        "id": "FAMbwUl026J7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "\n",
        "# Get the model size in bytes then convert to megabytes\n",
        "pretrained_effnetb2_food101_big_model_size = Path(\"models\", effnetb2_food101_big_model_path).stat().st_size // (1024*1024) # division converts bytes to megabytes (roughly)\n",
        "print(f\"Pretrained EffNetB2 feature extractor Food101_big model size: {pretrained_effnetb2_food101_big_model_size} MB\")"
      ],
      "metadata": {
        "id": "pz0X-vC526Hl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pipQZmFU26E0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}