{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39e49650-8af3-4a1d-8dfe-f3e6e8be7d86",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hnikolov\\AppData\\Local\\Temp\\ipykernel_9624\\3232613534.py:29: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  x = np.zeros((len(sentences), SEQ_LENGTH, len(characters)), dtype=np.bool)\n",
      "C:\\Users\\hnikolov\\AppData\\Local\\Temp\\ipykernel_9624\\3232613534.py:30: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y = np.zeros((len(sentences), len(characters)), dtype=np.bool)\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "651/651 [==============================] - 39s 57ms/step - loss: 2.6987\n",
      "Epoch 2/4\n",
      "651/651 [==============================] - 40s 62ms/step - loss: 2.3021\n",
      "Epoch 3/4\n",
      "651/651 [==============================] - 41s 62ms/step - loss: 2.1907\n",
      "Epoch 4/4\n",
      "651/651 [==============================] - 41s 63ms/step - loss: 2.1104\n",
      "INFO:tensorflow:Assets written to: textgenerator.model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: textgenerator.model\\assets\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Activation\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "filepath = tf.keras.utils.get_file('shakespeare.txt',\n",
    "                             'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')\n",
    "\n",
    "text = open(filepath, 'rb').read().decode(encoding='utf-8').lower()\n",
    "\n",
    "text = text[300_000: 800_000]\n",
    "\n",
    "characters = sorted(set(text))\n",
    "char_to_index = dict((c, i) for i, c in enumerate(characters))\n",
    "index_to_char = dict((i, c) for i, c in enumerate(characters))\n",
    "\n",
    "SEQ_LENGTH = 40\n",
    "STEP_SIZE = 3\n",
    "\n",
    "sentences = []\n",
    "next_char = []\n",
    "\n",
    "for i in range(0, len(text) - SEQ_LENGTH, STEP_SIZE):\n",
    "    sentences.append(text[i: i+SEQ_LENGTH])\n",
    "    next_char.append(text[i+SEQ_LENGTH])\n",
    "\n",
    "x = np.zeros((len(sentences), SEQ_LENGTH, len(characters)), dtype=np.bool)\n",
    "y = np.zeros((len(sentences), len(characters)), dtype=np.bool)\n",
    "\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, character in enumerate(sentence):\n",
    "        x[i, t, char_to_index[character]] = 1\n",
    "    y[i, char_to_index[next_char[i]]] = 1\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(SEQ_LENGTH, len(characters))))\n",
    "model.add(Dense(len(characters)))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(lr=0.01))\n",
    "\n",
    "model.fit(x, y, batch_size=256, epochs=4)\n",
    "\n",
    "model.save('textgenerator.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "64e27d01-401a-474d-86a3-f4969225f9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('textgenerator.model')\n",
    "\n",
    "def sample(preds, temperature=1.0):\n",
    "    preds = np.array(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)\n",
    "\n",
    "def generate_text(lenght, temperature):\n",
    "    start_index = random.randint(0, len(text) - SEQ_LENGTH - 1)\n",
    "    generated = ''\n",
    "    sentence = text[start_index: start_index+SEQ_LENGTH]\n",
    "    generated += sentence\n",
    "    for i in range(lenght):\n",
    "        x = np.zeros((1, SEQ_LENGTH, len(characters)))\n",
    "        for t, character in enumerate(sentence):\n",
    "            x[0, t, char_to_index[character]] = 1\n",
    "\n",
    "        predictions = model.predict(x, verbose=0)[0]\n",
    "        next_index = sample(predictions, temperature)\n",
    "        next_character = index_to_char[next_index]\n",
    "\n",
    "        generated += next_character\n",
    "        sentence = sentence[1:] + next_character\n",
    "    return generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d9aa9bbd-cc22-472d-8de1-dff4d2da9fc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---0.2---\n",
      "lling out a suit;\n",
      "and sometime comes shere the hath the seath the cand the hand the cand the hing the hing the hard the will the pare the will the here the will the his the hard the callore the hand the the pare the sand the cander the hear the hard in the have the will the here the will the hare the ward the his mand and the his the ward\n",
      "---0.4---\n",
      "h sight to be shown,\n",
      "but to rejoice in seare thou for male this deall sis thit with that the wall the hath me he me that the the cand and his the hand it heprist in the cand in the have of the here the and the hald that the prist the the this dowe the beath the will we the ines dowe the hish mace mane thear the king with not the ay the hi\n",
      "---0.6---\n",
      "n that side yours.\n",
      "now is this golden crave the willl thay sterf they mise this the warn, my pich thou hald then sins, the is if and the thoul youllles and whit this not me wind this that the ance whe ind bether will hers ptothen,\n",
      "thou hear he fay the eave to nors with sould hee what the here ie ghaus my sofred the teith on to say mery th\n",
      "---0.8---\n",
      "urs, and i am yours, and all.\n",
      "\n",
      "henry boll dithe there the peand\n",
      "or mare thas,\n",
      "you stith ount besed high wandin thau as mayd rost dear yourod thou hing\n",
      "coliowh thing thes me in sealins dothee ding whis bat'ss and tous fearse wizwhlrdest thil eich resart at, mine the tie,\n",
      "to ee shas bot his cours catnos to pirghiles tald erse meor nfim\n",
      "que \n",
      "---0.9---\n",
      "ll hence forthwith unto the sanctuary,\n",
      "thaling honking:\n",
      "is ward by the hink:\n",
      "the cald ves at ' hespied rate i havenow.\n",
      "the liover: wo wed, is more this delcur ofarmes, thener the mamr te se cate steirhe's fint brock.\n",
      "\n",
      "daesher:\n",
      "im whald the harking'se the inef fireclans bemel, you the laines\n",
      "will whis will avaks mard seor thougr wirthet st\n",
      "---1---\n",
      "ng none,\n",
      "come, go with me.\n",
      "go, sirrah, the wibl'd feall bon, this hicl ourt rise,\n",
      "you hy in a yammatth, came\n",
      "looving!\n",
      "cliswils; a camy in hencutich or bethers me:\n",
      "anwersso hor cowreol hi will;\n",
      "tay mesengst lod; farting of loure'd hok om culliswel, dach of tertherf'st momenreny thoum-n wathis owred.\n",
      "bory liof'y, afe y to liselo stoon, weat\n"
     ]
    }
   ],
   "source": [
    "print('---0.2---')\n",
    "print(generate_text(300, 0.2))\n",
    "print('---0.4---')\n",
    "print(generate_text(300, 0.4))\n",
    "print('---0.6---')\n",
    "print(generate_text(300, 0.6))\n",
    "print('---0.8---')\n",
    "print(generate_text(300, 0.8))\n",
    "print('---0.9---')\n",
    "print(generate_text(300, 0.9))\n",
    "print('---1---')\n",
    "print(generate_text(300, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51cf04d0-48dd-45cb-a333-62bf4fd6e599",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
